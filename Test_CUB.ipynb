{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test in CUB Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import imp\n",
    "import utils\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "imp.reload(utils)\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "\n",
    "INPUT_DIM = 640\n",
    "OUTPUT_DIM = 10\n",
    "base_features_path = \"./data/cub.pkl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datater = utils.Data()\n",
    "f_matrix,labels,means,covs = datater.read_data(base_features_path,INPUT_DIM,0,10,'cub')\n",
    "f_matrix = (f_matrix-np.min(f_matrix))/np.max(f_matrix)\n",
    "print(means.shape)\n",
    "x_train,x_test,y_train,y_test = utils.split_dataset(f_matrix,labels,4) # 划分数据集\n",
    "print(x_train.shape,x_test.shape)\n",
    "_,x_some,_,y_some = utils.split_dataset(x_train,y_train,25)\n",
    "print(x_some.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test of undistilled data \n",
    "acc = utils.logistic_test(x_train,y_train,x_test,y_test)\n",
    "acc_some = utils.logistic_test(x_some,y_some,x_test,y_test)\n",
    "print(\"Logistic Acc (all):{0},Logistic Acc (some):{1}\".format(acc,acc_some))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the PE-based model\n",
    "model = utils.MCC(input_dim=INPUT_DIM, output_dim=OUTPUT_DIM)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.1, weight_decay=5e-3)\n",
    "utils.train(model,optimizer,x_train,y_train,0.1)\n",
    "W1 = model.fc1.weight.clone().detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visulization data fearures with t-SNE\n",
    "f_new = f_matrix@W1.T\n",
    "tsne = TSNE()\n",
    "out = tsne.fit_transform(f_new)\n",
    "plt.figure(figsize=(10,10))\n",
    "for i in range(10):\n",
    "    indices = labels == i\n",
    "    x, y = out[indices].T\n",
    "    plt.scatter(x, y, label=str(i))\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the PE-based method with sampling data\n",
    "x_r_new = x_some@W1.T\n",
    "x_t_new = x_test@W1.T\n",
    "acc = utils.logistic_test(x_r_new,y_some,x_t_new,y_test)\n",
    "print(\"The acc of PEM (logistic) is:\",acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### New_class_add"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a new class data\n",
    "n_matrix,n_labels,_,_ = datater.read_data(base_features_path,INPUT_DIM,10,11,'mini')\n",
    "nx_train,nx_test,ny_train,ny_test = utils.split_dataset(n_matrix,n_labels,4)\n",
    "nnx_train = np.vstack((x_some,nx_train))\n",
    "nny_train = np.hstack((y_some,ny_train))\n",
    "nx_test = np.vstack((x_test,nx_test))\n",
    "ny_test = np.hstack((y_test,ny_test))\n",
    "acc = utils.logistic_test(nnx_train,nny_train,nx_test,ny_test) # 测试Logistic model的准确性\n",
    "print(\"Logistic Acc (some + new_class) acc:{0}\".format(acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform the smapling process\n",
    "upper = utils.Distill(10)\n",
    "x_up,y_up = upper.upsampling(x_some@W1.T,y_some,300)\n",
    "npx_train = np.vstack((x_up,nx_train@W1.T))\n",
    "npy_train = np.hstack((y_up,ny_train))\n",
    "acc = utils.logistic_test(npx_train,npy_train,nx_test@W1.T,ny_test) # 测试Logistic model的准确性\n",
    "print(\"Logistic PEM Acc (sampling) acc:{0}\".format(acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model again\n",
    "npx = npx_train\n",
    "model = utils.MCC(input_dim=OUTPUT_DIM, output_dim=OUTPUT_DIM)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.1, weight_decay=5e-4)\n",
    "utils.train(model,optimizer,npx,npy_train)\n",
    "W2 = model.fc1.weight.clone().detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the result\n",
    "x_r_new = npx@W2.T\n",
    "x_t_new = nx_test@W1.T\n",
    "x_t_new = x_t_new@W2.T\n",
    "acc = utils.logistic_test(x_r_new,npy_train,x_t_new,ny_test)\n",
    "print(\"Logistic PEM Acc (smapling + PEM) acc:{0}\".format(acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge a class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To add merge class, we first split the data set.\n",
    "n_matrix,n_labels,_,_ = datater.read_data(base_features_path,INPUT_DIM,17,18,'mini')\n",
    "n_labels = 8*np.ones(n_labels.shape)\n",
    "nx_train,nx_test,ny_train,ny_test = utils.split_dataset(n_matrix,n_labels,4)\n",
    "nnx_train = np.vstack((x_some,nx_train))\n",
    "nny_train = np.hstack((y_some,ny_train))\n",
    "nx_test = np.vstack((x_test,nx_test))\n",
    "ny_test = np.hstack((y_test,ny_test))\n",
    "acc = utils.logistic_test(nnx_train,nny_train,nx_test,ny_test) # 测试Logistic model的准确性\n",
    "print(\"Logistic Acc (some + new_class) acc:{0}\".format(acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform the smapling process\n",
    "upper = utils.Distill(10)\n",
    "x_up,y_up = upper.upsampling(x_some@W1.T,y_some,300)\n",
    "npx_train = np.vstack((x_up,nx_train@W1.T))\n",
    "npy_train = np.hstack((y_up,ny_train))\n",
    "acc = utils.logistic_test(npx_train,npy_train,nx_test@W1.T,ny_test) # 测试Logistic model的准确性\n",
    "print(\"Logistic PEM Acc (sampling) acc:{0}\".format(acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model again\n",
    "npx = npx_train\n",
    "model = utils.MCC(input_dim=OUTPUT_DIM, output_dim=OUTPUT_DIM,)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.1, weight_decay=5e-4)\n",
    "utils.train(model,optimizer,npx,npy_train)\n",
    "W2 = model.fc1.weight.clone().detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the result\n",
    "x_r_new = npx@W2.T\n",
    "x_t_new = nx_test@W1.T\n",
    "x_t_new = x_t_new@W2.T\n",
    "acc = utils.logistic_test(x_r_new,npy_train,x_t_new,ny_test)\n",
    "print(\"Logistic PEM Acc (smapling + PEM) acc:{0}\".format(acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DataSet Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we show the index. The index is the relative in idx in a class.\n",
    "# The upper.refine() will get the real features.\n",
    "upper = utils.Distill(10)\n",
    "x_id,y_id = upper.select_sample(x_train@W1.T,y_train)\n",
    "print(x_id,y_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
